ðŸ”§ TASK:
Enhance the current cryptocurrency trading system with explainable AI capabilities and user-facing model interpretation. Do not modify or remove any existing components â€” only extend.

ðŸŽ¯ OBJECTIVE:
Add a fully integrated explainability layer that allows users to understand why a specific trading decision (buy/sell/hold) was made by the AI model. This should function for each symbol independently and appear on the frontend.

ðŸ§  FEATURES TO IMPLEMENT:

1. âœ… Trade Reason Module:
   - Create a new AI inference logger that captures:
     â€¢ Selected strategy/model name (e.g., LSTM, Transformer, GradientBoost)
     â€¢ Top 3 contributing features (e.g., EMA crossover, RSI breakout, Volume spike)
     â€¢ Signal strength/confidence score (e.g., 84% BUY confidence)

2. âœ… Explainable AI Panel:
   - Build a new `/explain` page and component on the main dashboard that:
     â€¢ Shows the last 5 executed trades with their AI explanations
     â€¢ Uses visual elements (icons, colors) to represent bullish/bearish factors
     â€¢ Includes timestamps, pair name, model used, and reason summary

3. âœ… Confidence-based Highlighting:
   - Add color-coding or tags (e.g., Strong Buy, Neutral, Weak Signal) based on AI signal strength.
   - Display this next to the current strategy status per trading pair.

4. âœ… API Endpoint:
   - Create `/api/ai/explanation/<symbol>` to return structured JSON including:
     â€¢ Model used
     â€¢ Features that triggered the decision
     â€¢ Final decision and confidence score

âš ï¸ Constraints:
â€¢ No change to core execution logic or trading engine
â€¢ Must use existing data sources (OKX, internal features)
â€¢ Store explanations in memory or lightweight DB (no heavy writes)
â€¢ UI should blend with current design system

âœ… Example Output:

{
  "symbol": "BTC/USDT",
  "model": "Transformer",
  "decision": "BUY",
  "confidence": 91,
  "top_features": ["RSI = 31 (oversold)", "EMA(20) > EMA(50)", "High volume surge"],
  "timestamp": "2025-06-08T13:12:05Z"
}

Once completed, let me know so I can verify the new Explainable AI functionality.